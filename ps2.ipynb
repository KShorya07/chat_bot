{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YRI6_8TpnLOk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeEmbedding(nn.Module):\n",
        "    def __init__(self, n_embd=320):\n",
        "        super().__init__()\n",
        "        self.linear_1 = nn.Linear(1, n_embd)\n",
        "        self.linear_2 = nn.Linear(n_embd, n_embd)\n",
        "\n",
        "    def forward(self, t):\n",
        "        x = self.linear_1(t)\n",
        "        x = F.silu(x)\n",
        "        x = self.linear_2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "MThcLgSrsVWo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNET_ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, n_time=320):\n",
        "        super().__init__()\n",
        "        num_groups_feature = min(in_channels, 32)\n",
        "        num_groups_merged = min(out_channels, 32) # Also apply to the merged groupnorm\n",
        "\n",
        "        self.groupnorm_feature = nn.GroupNorm(num_groups_feature, in_channels)\n",
        "        self.conv_feature = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.linear_time = nn.Linear(n_time, out_channels)\n",
        "        self.groupnorm_merged = nn.GroupNorm(num_groups_merged, out_channels)\n",
        "        self.conv_merged = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.residual_layer = nn.Identity() if in_channels == out_channels else nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, feature, time):\n",
        "        residue = feature\n",
        "        x = F.silu(self.groupnorm_feature(feature))\n",
        "        x = self.conv_feature(x)\n",
        "        time = F.silu(time)\n",
        "        time = self.linear_time(time).unsqueeze(-1).unsqueeze(-1)\n",
        "        merged = x + time\n",
        "        merged = F.silu(self.groupnorm_merged(merged))\n",
        "        merged = self.conv_merged(merged)\n",
        "        return merged + self.residual_layer(residue)"
      ],
      "metadata": {
        "id": "WFbIPdNnuG2g"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Upsample(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.interpolate(x, scale_factor=2, mode='nearest')\n",
        "        return self.conv(x)"
      ],
      "metadata": {
        "id": "0QM3iQOBuhX4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNET(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=3): # Default to 3 for RGB images\n",
        "        super().__init__()\n",
        "        self.enc1 = UNET_ResidualBlock(in_channels, 128)\n",
        "        self.enc2 = UNET_ResidualBlock(128, 256)\n",
        "\n",
        "        # Bottleneck:\n",
        "        self.bottleneck = UNET_ResidualBlock(256, 256)\n",
        "\n",
        "        # Decoding\n",
        "        self.dec1 = UNET_ResidualBlock(256, 128)\n",
        "        self.dec2 = UNET_ResidualBlock(128, out_channels) # Output channels for the UNET\n",
        "\n",
        "    def forward(self, x, time_emb):\n",
        "        x = self.enc1(x, time_emb)\n",
        "        x = self.enc2(x, time_emb)\n",
        "        x = self.bottleneck(x, time_emb)\n",
        "        x = self.dec1(x, time_emb)\n",
        "        x = self.dec2(x, time_emb)\n",
        "        return x"
      ],
      "metadata": {
        "id": "XDE5bsNxumTs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNET_OutputLayer(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        num_groups = max(1, min(32, in_channels))\n",
        "        self.groupnorm = nn.GroupNorm(num_groups, in_channels)\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.silu(self.groupnorm(x))\n",
        "        x = self.conv(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "W57M03GTuvR5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Diffusion(nn.Module):\n",
        "    def __init__(self, in_channels=3, unet_output_channels=3):\n",
        "        super().__init__()\n",
        "        self.time_embedding = TimeEmbedding(320)\n",
        "        self.unet = UNET(in_channels=in_channels, out_channels=unet_output_channels)\n",
        "        self.final = UNET_OutputLayer(unet_output_channels, unet_output_channels)\n",
        "\n",
        "    def forward(self, latent, time):\n",
        "        time = self.time_embedding(time)\n",
        "        x = self.unet(latent, time)\n",
        "        x = self.final(x)# final predicted noise\n",
        "        return x"
      ],
      "metadata": {
        "id": "kYzQIm1au0SJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reverse_diffusion(diffusion_model, scheduler, shape, device):\n",
        "    B, C, H, W = shape\n",
        "    x_t = torch.randn(shape, device=device)\n",
        "\n",
        "    for t in reversed(range(scheduler.T)):\n",
        "        beta_t, alpha_t, alpha_hat_t = scheduler.get(t)\n",
        "        time_tensor = torch.full((B, 1), t / scheduler.T, device=device)\n",
        "\n",
        "\n",
        "        predicted_noise = diffusion_model(x_t, time_tensor)\n",
        "\n",
        "        # reverse step\n",
        "        x_t = (x_t - beta_t * predicted_noise) / torch.sqrt(alpha_t)\n",
        "\n",
        "    return x_t"
      ],
      "metadata": {
        "id": "Fi7QlJF4vcGW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DiffusionScheduler:\n",
        "    def __init__(self, T=1000, beta_start=1e-4, beta_end=0.02, device=\"cpu\"):\n",
        "        self.T = T\n",
        "        self.device = device\n",
        "\n",
        "        self.beta = torch.linspace(beta_start, beta_end, T, device=device)\n",
        "        self.alpha = 1.0 - self.beta\n",
        "        self.alpha_bar = torch.cumprod(self.alpha, dim=0)\n",
        "\n",
        "    def get(self, t):\n",
        "        return self.beta[t], self.alpha[t], self.alpha_bar[t]\n"
      ],
      "metadata": {
        "id": "GAhZmJJfvf_b"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_diffusion(x0, t,scheduler):\n",
        "\n",
        "   noise=torch.randn_like(x0)\n",
        "\n",
        "   _,_, alpha_bar_t=scheduler.get(t)\n",
        "   xt=torch.sqrt(alpha_bar_t)*x0 + torch.sqrt(1-alpha_bar_t)*noise\n",
        "\n",
        "   return xt,noise\n"
      ],
      "metadata": {
        "id": "lEA4yk0nhTPB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "diffusion_model = Diffusion(in_channels=3, unet_output_channels=3).to(device)\n",
        "scheduler = DiffusionScheduler(T=50, device=device)\n",
        "\n",
        "# Taking Fake image (for demo)\n",
        "x0 = torch.randn(1, 3, 64, 64, device=device)\n",
        "\n",
        "# Forward diffusion example\n",
        "t = torch.randint(0, scheduler.T, (1,), device=device)\n",
        "xt, _ = forward_diffusion(x0, t, scheduler)\n",
        "\n",
        "# Reverse diffusion (sampling)\n",
        "generated_image = reverse_diffusion(\n",
        "    diffusion_model,\n",
        "    scheduler,\n",
        "    shape=(1, 3, 64, 64),\n",
        "    device=device\n",
        ")\n",
        "\n",
        "generated_image = torch.clamp(generated_image, -1, 1)\n",
        "generated_image = (generated_image + 1) / 2  # normalize to [0,1]\n",
        "\n",
        "\n",
        "img_np = generated_image[0].permute(1, 2, 0).cpu().detach().numpy()\n",
        "plt.imshow(img_np)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Generated Image (DDPM Demo)\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Generated image shape:\", generated_image.shape)"
      ],
      "metadata": {
        "id": "pp3LLCZVVpRe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}